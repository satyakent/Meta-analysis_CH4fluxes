---
title: "Regression tree modeling: CH4 wetland fluxes"
author: "Satya Kent"
date: "2024-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Load data and reorganize for regression tree modeling 
```{r}
library(tidyverse)

flux_rates=read_csv("flux_rates_meta-analysis.csv")

# Specify the order of x-axis categories
desired_order2 <- c("Methanogenesis", "Aerobic methane oxidation", "Anaerobic methane oxidation")

# Convert "Pathway" column to factor with desired order
flux_rates$Pathway <- factor(flux_rates$Pathway, levels = desired_order2)

#create filtered dataframe with all the environmental variables I care about.
flux_rates_filtered <- flux_rates[, c("Pathway", "Mean_rate", "Wetland_type", "Inc_temp", "Inc_length_days","Depth_representative", "Salinity_ppt", "Salinity_cat", "dom_veg", "method","subpathway")]


library(dplyr)

#replace NAs with 'Not Reported' for categorical columns.
flux_rates_filtered2 <- flux_rates_filtered %>%
  mutate(dom_veg = ifelse(is.na(dom_veg), "Not Reported", dom_veg),
         subpathway = ifelse(is.na(subpathway), "Not Reported", subpathway),
         Wetland_type = ifelse(is.na(Wetland_type), "Not Reported", Wetland_type),
         Salinity_cat = ifelse(is.na(Salinity_cat), "Not Reported", Salinity_cat))

# remove the continuous salinity column
flux_rates_filtered2 <- flux_rates_filtered2 %>%
  dplyr::select(-Salinity_ppt)

#re-organize datasets for regression tree modeling 
MGEN_filtered=flux_rates_filtered2[flux_rates_filtered2$Pathway == "Methanogenesis", ]
MGEN_filtered$Pathway <- NULL
names(MGEN_filtered) <- c("Mean_rate", "Wetland type", "Incubation temperature", "Incubation length", "Depth", "Salinity", "Dominant vegetation", "Method", "Subpathway")


MOX_filtered=flux_rates_filtered2[flux_rates_filtered2$Pathway == "Aerobic methane oxidation", ]
MOX_filtered$Pathway <- NULL
names(MOX_filtered) <- c("Mean_rate", "Wetland type", "Incubation temperature", "Incubation length", "Depth","Salinity", "Dominant vegetation", "Method", "Subpathway")
MOX_filtered$Subpathway <- NULL #no subpathways exist for MOx

AOM_filtered=flux_rates_filtered2[flux_rates_filtered2$Pathway == "Anaerobic methane oxidation", ]
AOM_filtered$Pathway <- NULL
names(AOM_filtered) <- c("Mean_rate", "Wetland type", "Incubation temperature", "Incubation length", "Depth", "Salinity", "Dominant vegetation", "Method", "Subpathway")
```

Univariate regression tree: methanogenesis
```{r}

#packages for regression trees
library(rpart)
library(rpart.plot)

set.seed(123)
tree_univariate_mgen <- rpart(Mean_rate ~. , data = MGEN_filtered, method = "anova")

#visualize the tree
rpart.plot(tree_univariate_mgen)

#let's check the residuals
plot(predict(tree_univariate_mgen),residuals(tree_univariate_mgen))

## Pruning the tree

#Goal: see if a smaller subtree can give us comparable results to the fully grown tree. If yes, we should go for the simpler tree because it reduces the likelihood of overfitting.

#A robust strategy of pruning the tree consists of avoiding splitting a partition if the split does not significantly improve the overall quality of the model.

#In the rpart package, this is controlled by the complexity parameter (cp), which imposes a penalty to the tree for having two many splits. The default value in rpart() is 0.01. The higher the cp, the smaller the tree.

#A too small value of cp leads to overfitting and a too large cp value will result in a too small tree. Both cases decrease the predictive performance of the model.

#An optimal cp value can be estimated by testing different cp values and using cross-validation approaches to determine the corresponding prediction accuracy of the model. The best cp is then defined as the one that maximizes the cross-validation accuracy.

# In the plot generated by plotcp(), "A good choice of cp for pruning is often the leftmost value for which the mean lies below the horizontal line"
# Here, this is cp = 0.093

plotcp(tree_univariate_mgen)

#Prints a table of optimal prunings based on a complexity parameter
printcp(tree_univariate_mgen)

#visualize more levels
tree_univariate_mgen2 <- rpart(Mean_rate ~. , data = MGEN_filtered, method = "anova", control=list(cp=0,xval=10))

plotcp(tree_univariate_mgen2)

printcp(tree_univariate_mgen2)

# Prune the model based on the optimal cp value
tree_uni_mgen_pruned <- prune(tree_univariate_mgen, cp = 0.093)

rpart.plot(tree_uni_mgen_pruned)

printcp(tree_uni_mgen_pruned)


#let's check the residuals
plot(predict(tree_uni_mgen_pruned),residuals(tree_uni_mgen_pruned))


#Extract importance values from tree
importance = tree_uni_mgen_pruned$variable.importance

importance_df = data.frame(
  Feature = names(importance),
  Importance = importance
)

importance_df = importance_df[order(-importance_df$Importance),]

#Gini importance 
ggplot(importance_df, aes(x=reorder(Feature, -Importance), y=Importance))+
  geom_col()+
  theme_minimal()+
  labs(title="Feature Importance: Methanogenesis ",
       x="Features", 
       y= "Gini Importance")+
  theme(axis.text.x = element_text(angle = 45, hjust =1))

## Calculate the sum of importance scores
total_importance <- sum(importance_df$Importance)

# Normalize importance scores
importance_df$Normalized_Importance <- importance_df$Importance / total_importance

# Plot the normalized importance scores
ggplot(importance_df, aes(x=reorder(Feature, -Normalized_Importance), y=Normalized_Importance)) +
  geom_col() +
  theme_minimal() +
  labs(title="Relative Feature Importance: MGEN",
       x = NULL, 
       y= "Gini Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust =1))


#Permutation importance 

# Initial model performance evaluation
original_perf <- with(MGEN_filtered, mean((Mean_rate - predict(tree_uni_mgen_pruned, newdata = MGEN_filtered))^2))

# Storage for importance scores
feature_importance <- setNames(numeric(ncol(MGEN_filtered) - 1), names(MGEN_filtered)[-which(names(MGEN_filtered) == "Mean_rate")])

# Calculate importance for each feature
set.seed(123)  # For reproducibility
for (feature in names(feature_importance)) {
  # Copy the original data
  data_permuted <- MGEN_filtered
 
  # Permute the feature column
  data_permuted[[feature]] <- sample(data_permuted[[feature]])
 
  # Calculate performance with permuted data
  permuted_perf <- with(data_permuted, mean((Mean_rate - predict(tree_uni_mgen_pruned, newdata = data_permuted))^2))
 
  # Importance score is the loss in performance
  feature_importance[feature] <- permuted_perf - original_perf
}

# Sorting features by importance
feature_importance <- sort(feature_importance, decreasing = TRUE)

# Print the importance
print(feature_importance)

# Convert to data frame for ggplot
importance_df <- data.frame(Feature = names(feature_importance), Importance = feature_importance)

# Plot
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Permutation Importance: Methanogenesis", x = NULL, y = "Decrease in Performance (MSE)") +
  theme(axis.text.x = element_text(angle = 65, hjust = 1))

```

Shapley values: methanogenesis
```{r}

# Load necessary libraries
library(kernelshap)
library(shapviz)
library(ggplot2)


# Set seed for reproducibility
set.seed(123)

# Define the full dataset for both rows to be explained and background data. I'm doing this since my dataset is so small (n=93).

X <- MGEN_filtered[, -which(names(MGEN_filtered) == "Mean_rate")]  # Exclude target variable
bg_X <- X  # Use the same dataset for background data

# Define a prediction function for the model
pred_fn <- function(model, newdata) {
  predict(model, newdata = newdata)
}

# Calculate SHAP values using kernelshap
shap_values <- kernelshap(tree_uni_mgen_pruned, X = X, bg_X = bg_X, pred_wrapper = pred_fn, nsim = 100)

# Convert SHAP values to a shapviz object for analysis
shap_viz <- shapviz(shap_values)

# Analyze and visualize SHAP values

# Plot feature importance
sv_importance(shap_viz) #looks similar to permutation importance plot
sv_importance(shap_viz, kind = "bee") # plot that shows directionality is not well suited to my dataset bc the most important predictors (dominant vegetation, wetland type) are categorical.  

```

Univariate regression tree: MOx
```{r}

#packages for regression trees
library(rpart)
library(rpart.plot)

set.seed(123)
tree_univariate_MOX <- rpart(Mean_rate ~. , data = MOX_filtered, method = "anova")

#visualize the tree
rpart.plot(tree_univariate_MOX)

#let's check the residuals
plot(predict(tree_univariate_MOX),residuals(tree_univariate_MOX))

## Pruning the tree

#"Our goal here is to see if a smaller subtree can give us comparable results to the fully grown tree. If yes, we should go for the simpler tree because it reduces the likelihood of overfitting.

#One possible robust strategy of pruning the tree (or stopping the tree to grow) consists of avoiding splitting a partition if the split does not significantly improves the overall quality of the model.

#In rpart package, this is controlled by the complexity parameter (cp), which imposes a penalty to the tree for having two many splits. The default value is 0.01. The higher the cp, the smaller the tree.

#A too small value of cp leads to overfitting and a too large cp value will result to a too small tree. Both cases decrease the predictive performance of the model.

#An optimal cp value can be estimated by testing different cp values and using cross-validation approaches to determine the corresponding prediction accuracy of the model. The best cp is then defined as the one that maximizes the cross-validation accuracy.

# In plotcp() "A good choice of cp for pruning is often the leftmost value for which the mean lies below the horizontal line"
# Here, this is cp = 0.057

plotcp(tree_univariate_MOX)

#Prints a table of optimal prunings based on a complexity parameter
printcp(tree_univariate_MOX)

#visualize more levels
tree_univariate_MOX2 <- rpart(Mean_rate ~. , data = MOX_filtered, method = "anova", control=list(cp=0,xval=10))

plotcp(tree_univariate_MOX2)

printcp(tree_univariate_MOX2)

# Prune the model based on the optimal cp value
tree_uni_MOX_pruned <- prune(tree_univariate_MOX, cp = 0.057)

rpart.plot(tree_uni_MOX_pruned)

printcp(tree_uni_MOX_pruned)


#let's check the residuals
plot(predict(tree_uni_MOX_pruned),residuals(tree_uni_MOX_pruned))


#Extract importance values from tree
importance = tree_uni_MOX_pruned$variable.importance

importance_df = data.frame(
  Feature = names(importance),
  Importance = importance
)

importance_df = importance_df[order(-importance_df$Importance),]

#Gini importance 
ggplot(importance_df, aes(x=reorder(Feature, -Importance), y=Importance))+
  geom_col()+
  theme_minimal()+
  labs(title="Feature Importance: MOx ",
       x="Features", 
       y= "Gini Importance")+
  theme(axis.text.x = element_text(angle = 45, hjust =1))

## Calculate the sum of importance scores
total_importance <- sum(importance_df$Importance)

# Normalize importance scores
importance_df$Normalized_Importance <- importance_df$Importance / total_importance

# Plot the normalized importance scores
ggplot(importance_df, aes(x=reorder(Feature, -Normalized_Importance), y=Normalized_Importance)) +
  geom_col() +
  theme_minimal() +
  labs(title="Relative Feature Importance: MOx",
       x = NULL, 
       y= "Gini Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust =1))


#Permutation importance 

# Initial model performance evaluation
original_perf <- with(MOX_filtered, mean((Mean_rate - predict(tree_uni_MOX_pruned, newdata = MOX_filtered))^2))

# Storage for importance scores
feature_importance <- setNames(numeric(ncol(MOX_filtered) - 1), names(MOX_filtered)[-which(names(MOX_filtered) == "Mean_rate")])

# Calculate importance for each feature
set.seed(123)  # For reproducibility
for (feature in names(feature_importance)) {
  # Copy the original data
  data_permuted <- MOX_filtered
 
  # Permute the feature column
  data_permuted[[feature]] <- sample(data_permuted[[feature]])
 
  # Calculate performance with permuted data
  permuted_perf <- with(data_permuted, mean((Mean_rate - predict(tree_uni_MOX_pruned, newdata = data_permuted))^2))
 
  # Importance score is the loss in performance
  feature_importance[feature] <- permuted_perf - original_perf
}

# Sorting features by importance
feature_importance <- sort(feature_importance, decreasing = TRUE)

# Print the importance
print(feature_importance)

# Convert to data frame for ggplot
importance_df <- data.frame(Feature = names(feature_importance), Importance = feature_importance)

# Plot
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Permutation Importance: MOx", x = NULL, y = "Decrease in Performance (MSE)") +
  theme(axis.text.x = element_text(angle = 65, hjust = 1))



```

Shapley values: MOx
```{r}

# Load necessary libraries
library(kernelshap)
library(shapviz)
library(ggplot2)


# Set seed for reproducibility
set.seed(123)

# Define the full dataset for both rows to be explained and background data. I'm doing this since my dataset is so small (n=93).

X <- MOX_filtered[, -which(names(MOX_filtered) == "Mean_rate")]  # Exclude target variable
bg_X <- X  # Use the same dataset for background data

# Define a prediction function for the model
pred_fn <- function(model, newdata) {
  predict(model, newdata = newdata)
}

# Calculate SHAP values using kernelshap
shap_values <- kernelshap(tree_uni_MOX_pruned, X = X, bg_X = bg_X, pred_wrapper = pred_fn, nsim = 100)

# Convert SHAP values to a shapviz object for analysis
shap_viz <- shapviz(shap_values)

# Analyze and visualize SHAP values

# Plot feature importance
sv_importance(shap_viz) #looks similar to permutation importance plot
sv_importance(shap_viz, kind = "bee") # plot that shows directionality is not well suited to my dataset bc the most important predictors (dominant vegetation, wetland type) are categorical.  

```

Univariate regression tree: AOM
```{r}

#packages for regression trees
library(rpart)
library(rpart.plot)

set.seed(123)
tree_univariate_AOM <- rpart(Mean_rate ~. , data = AOM_filtered, method = "anova")

#visualize the tree
rpart.plot(tree_univariate_AOM)

#let's check the residuals
plot(predict(tree_univariate_AOM),residuals(tree_univariate_AOM))

## Pruning the tree

#"Our goal here is to see if a smaller subtree can give us comparable results to the fully grown tree. If yes, we should go for the simpler tree because it reduces the likelihood of overfitting.

#One possible robust strategy of pruning the tree (or stopping the tree to grow) consists of avoiding splitting a partition if the split does not significantly improves the overall quality of the model.

#In rpart package, this is controlled by the complexity parameter (cp), which imposes a penalty to the tree for having two many splits. The default value is 0.01. The higher the cp, the smaller the tree.

#A too small value of cp leads to overfitting and a too large cp value will result to a too small tree. Both cases decrease the predictive performance of the model.

#An optimal cp value can be estimated by testing different cp values and using cross-validation approaches to determine the corresponding prediction accuracy of the model. The best cp is then defined as the one that maximizes the cross-validation accuracy.

# In plotcp() "A good choice of cp for pruning is often the leftmost value for which the mean lies below the horizontal line"
# Here, this is cp = 0.057

plotcp(tree_univariate_AOM)

#Prints a table of optimal prunings based on a complexity parameter
printcp(tree_univariate_AOM)

#visualize more levels
tree_univariate_AOM2 <- rpart(Mean_rate ~. , data = AOM_filtered, method = "anova", control=list(cp=0,xval=10))

plotcp(tree_univariate_AOM2)

printcp(tree_univariate_AOM2)

# Prune the model based on the optimal cp value
tree_uni_AOM_pruned <- prune(tree_univariate_AOM, cp = 0.012)

rpart.plot(tree_uni_AOM_pruned)

printcp(tree_uni_AOM_pruned)


#let's check the residuals
plot(predict(tree_uni_AOM_pruned),residuals(tree_uni_AOM_pruned))


#Extract importance values from tree
importance = tree_uni_AOM_pruned$variable.importance

importance_df = data.frame(
  Feature = names(importance),
  Importance = importance
)

importance_df = importance_df[order(-importance_df$Importance),]

#Gini importance 
ggplot(importance_df, aes(x=reorder(Feature, -Importance), y=Importance))+
  geom_col()+
  theme_minimal()+
  labs(title="Feature Importance: AOM ",
       x="Features", 
       y= "Gini Importance")+
  theme(axis.text.x = element_text(angle = 45, hjust =1))

## Calculate the sum of importance scores
total_importance <- sum(importance_df$Importance)

# Normalize importance scores
importance_df$Normalized_Importance <- importance_df$Importance / total_importance

# Plot the normalized importance scores
ggplot(importance_df, aes(x=reorder(Feature, -Normalized_Importance), y=Normalized_Importance)) +
  geom_col() +
  theme_minimal() +
  labs(title="Relative Feature Importance: AOM",
       x = NULL, 
       y= "Gini Importance") +
  theme(axis.text.x = element_text(angle = 45, hjust =1), )


#Permutation importance 

# Initial model performance evaluation
original_perf <- with(AOM_filtered, mean((Mean_rate - predict(tree_uni_AOM_pruned, newdata = AOM_filtered))^2))

# Storage for importance scores
feature_importance <- setNames(numeric(ncol(AOM_filtered) - 1), names(AOM_filtered)[-which(names(AOM_filtered) == "Mean_rate")])

# Calculate importance for each feature
set.seed(123)  # For reproducibility
for (feature in names(feature_importance)) {
  # Copy the original data
  data_permuted <- AOM_filtered
 
  # Permute the feature column
  data_permuted[[feature]] <- sample(data_permuted[[feature]])
 
  # Calculate performance with permuted data
  permuted_perf <- with(data_permuted, mean((Mean_rate - predict(tree_uni_AOM_pruned, newdata = data_permuted))^2))
 
  # Importance score is the loss in performance
  feature_importance[feature] <- permuted_perf - original_perf
}

# Sorting features by importance
feature_importance <- sort(feature_importance, decreasing = TRUE)

# Print the importance
print(feature_importance)

# Convert to data frame for ggplot
importance_df <- data.frame(Feature = names(feature_importance), Importance = feature_importance)

# Plot
ggplot(importance_df, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity") +
  theme_minimal() +
  labs(title = "Permutation Importance: AOM", x = NULL, y = "Decrease in Performance (MSE)") +
  theme(axis.text.x = element_text(angle = 65, hjust = 1))
```

Shapley values: AOM
```{r}

# Load necessary libraries
library(kernelshap)
library(shapviz)
library(ggplot2)


# Set seed for reproducibility
set.seed(123)

# Define the full dataset for both rows to be explained and background data. I'm doing this since my dataset is so small (n=93).

X <- AOM_filtered[, -which(names(AOM_filtered) == "Mean_rate")]  # Exclude target variable
bg_X <- X  # Use the same dataset for background data

# Define a prediction function for the model
pred_fn <- function(model, newdata) {
  predict(model, newdata = newdata)
}

# Calculate SHAP values using kernelshap
shap_values <- kernelshap(tree_uni_AOM_pruned, X = X, bg_X = bg_X, pred_wrapper = pred_fn, nsim = 100)

# Convert SHAP values to a shapviz object for analysis
shap_viz <- shapviz(shap_values)

# Analyze and visualize SHAP values

# Plot feature importance
sv_importance(shap_viz) #looks similar to permutation importance plot
sv_importance(shap_viz, kind = "bee") # plot that shows directionality is not well suited to my dataset bc the most important predictors (dominant vegetation, wetland type) are categorical.  

```

